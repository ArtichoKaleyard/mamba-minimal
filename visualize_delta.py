"""Mamba Delta å¯è§†åŒ–å·¥å…·

Delta (Î”) æ˜¯ Mamba çš„æ ¸å¿ƒåˆ›æ–°ï¼Œæ§åˆ¶çŠ¶æ€ç©ºé—´çš„ç¦»æ•£åŒ–æ­¥é•¿ã€‚
è¿™ä¸ªè„šæœ¬å¯è§†åŒ–ï¼š
    1. Delta å€¼çš„ç©ºé—´åˆ†å¸ƒï¼ˆpatch-wiseï¼‰
    2. Delta å€¼åœ¨ä¸åŒå±‚çš„æ¼”åŒ–
    3. Delta å€¼çš„ç»Ÿè®¡ç‰¹æ€§
    4. Delta å¯¹ä¸åŒè¾“å…¥çš„å“åº”æ¨¡å¼
    5. Delta ä¸æœ€ç»ˆé¢„æµ‹çš„å…³ç³»

ä½¿ç”¨æ–¹æ³•:
    python visualize_delta.py --model_path ./checkpoints/best_model.pth
"""

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import font_manager
import seaborn as sns
from scipy.ndimage import zoom
import argparse
from pathlib import Path
from tqdm import tqdm
from typing import List, Dict
import warnings

warnings.filterwarnings('ignore')

from vision_mamba import VisionMamba, create_vision_mamba_mnist

ENABLE_POS_EMBED = False  # æ˜¯å¦å¯ç”¨ä½ç½®ç¼–ç 


def configure_fonts():
    """é…ç½®å­—ä½“è®¾ç½®ï¼ˆLinuxå…¼å®¹ï¼‰"""
    # è·å–ç³»ç»Ÿæ‰€æœ‰å¯ç”¨å­—ä½“
    available_fonts = set(f.name for f in font_manager.fontManager.ttflist)
    
    # Linuxä¸Šå¸¸è§çš„ä¸­æ–‡å­—ä½“ä¼˜å…ˆçº§åˆ—è¡¨
    chinese_fonts = [
        'Noto Sans CJK SC',
        'Noto Sans CJK TC', 
        'Noto Serif CJK SC',
        'WenQuanYi Micro Hei',
        'WenQuanYi Zen Hei',
        'Droid Sans Fallback',
        'AR PL UMing CN',
        'AR PL UKai CN',
    ]
    
    # å¤‡ç”¨è‹±æ–‡å­—ä½“
    fallback_fonts = ['DejaVu Sans', 'Liberation Sans', 'Arial']
    
    # æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
    selected_font = None
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            break
    
    # å¦‚æœæ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡å­—ä½“
    if selected_font is None:
        for font in fallback_fonts:
            if font in available_fonts:
                selected_font = font
                break
    
    # è®¾ç½®å­—ä½“
    if selected_font:
        matplotlib.rcParams['font.sans-serif'] = [selected_font]
        matplotlib.rcParams['font.family'] = 'sans-serif'
        matplotlib.rcParams['axes.unicode_minus'] = False
        print(f"âœ“ å­—ä½“è®¾ç½®æˆåŠŸ: {selected_font}")
        return selected_font
    else:
        # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
        matplotlib.rcParams['font.family'] = 'sans-serif'
        matplotlib.rcParams['axes.unicode_minus'] = False
        print("âš  æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“")
        return 'default'


class DeltaVisualizer:
    """Delta å¯è§†åŒ–å™¨"""

    def __init__(self, model: VisionMamba, device: torch.device, save_dir: str = "./delta_viz"):
        self.model = model.to(device)
        self.model.eval()
        self.device = device
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # é…ç½®ç»˜å›¾æ ·å¼
        try:
            plt.style.use('seaborn-v0_8-darkgrid')
        except:
            plt.style.use('default')
        
        sns.set_palette("husl")

    def extract_delta_values(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """æå–æ‰€æœ‰å±‚çš„ delta å€¼

        Args:
            x: è¾“å…¥å›¾åƒ shape (1, 1, 28, 28)

        Returns:
            delta_dict: åŒ…å«å„å±‚ delta å€¼çš„å­—å…¸
        """
        deltas = {}

        with torch.no_grad():
            # Patch embedding
            x = self.model.patch_embed(x)  # (1, n_patches, d_model)
            if ENABLE_POS_EMBED:    # æ·»åŠ ä½ç½®ç¼–ç 
                x = x + self.model.pos_embed
            x = self.model.pos_drop(x)

            # éå†æ¯ä¸€å±‚ï¼Œæå– delta
            for layer_idx, layer in enumerate(self.model.layers):
                # é€šè¿‡ norm
                x_normed = layer.norm(x)

                # é€šè¿‡ in_proj
                x_and_res = layer.mixer.in_proj(x_normed)
                (x_proj, res) = x_and_res.split(
                    split_size=[layer.mixer.args.d_inner, layer.mixer.args.d_inner],
                    dim=-1
                )

                # é€šè¿‡ conv1d
                x_proj = x_proj.transpose(1, 2)  # (1, d_inner, n_patches)
                x_proj = layer.mixer.conv1d(x_proj)[:, :, :x.shape[1]]
                x_proj = x_proj.transpose(1, 2)  # (1, n_patches, d_inner)
                x_proj = torch.nn.functional.silu(x_proj)

                # æå– delta
                x_dbl = layer.mixer.x_proj(x_proj)  # (1, n_patches, dt_rank + 2*n)
                n = layer.mixer.A_log.shape[1]
                dt_rank = layer.mixer.args.dt_rank

                (delta, B, C) = x_dbl.split(split_size=[dt_rank, n, n], dim=-1)
                delta = torch.nn.functional.softplus(layer.mixer.dt_proj(delta))  # (1, n_patches, d_inner)

                # ä¿å­˜ delta
                deltas[f'layer_{layer_idx}'] = delta.squeeze(0).cpu()  # (n_patches, d_inner)

                # ç»§ç»­å‰å‘ä¼ æ’­
                x = layer(x)

        return deltas

    def plot_delta_spatial_distribution(
            self,
            image: np.ndarray,
            deltas: Dict[str, torch.Tensor],
            prediction: int,
            true_label: int,
            save_name: str = "delta_spatial.png"
    ):
        """å¯è§†åŒ– delta çš„ç©ºé—´åˆ†å¸ƒ

        Args:
            image: åŸå§‹å›¾åƒ (1, 28, 28)
            deltas: å„å±‚çš„ delta å€¼
            prediction: é¢„æµ‹æ ‡ç­¾
            true_label: çœŸå®æ ‡ç­¾
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_layers = len(deltas)
        fig, axes = plt.subplots(2, num_layers + 1, figsize=(4 * (num_layers + 1), 8))

        # è®¡ç®— patch ç½‘æ ¼å¤§å°
        n_patches = deltas['layer_0'].shape[0]
        grid_size = int(np.sqrt(n_patches))

        # ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—ï¼šæ˜¾ç¤ºåŸå›¾
        ax = axes[0, 0]
        # ax.imshow(image.squeeze(), cmap='gray')
        display_img = self.process_image_for_plot(image)
        ax.imshow(display_img)

        ax.set_title(f'Original\nTrue: {true_label}, Pred: {prediction}',
                     fontsize=11, fontweight='bold')
        ax.axis('off')

        # ç¬¬äºŒè¡Œç¬¬ä¸€åˆ—ï¼šç©ºç™½
        axes[1, 0].axis('off')

        # éå†æ¯ä¸€å±‚
        for layer_idx in range(num_layers):
            delta = deltas[f'layer_{layer_idx}']  # (n_patches, d_inner)

            # è®¡ç®—æ¯ä¸ª patch çš„å¹³å‡ deltaï¼ˆè·¨é€šé“å¹³å‡ï¼‰
            delta_mean = delta.mean(dim=1).numpy()  # (n_patches,)
            delta_std = delta.std(dim=1).numpy()  # (n_patches,)

            # é‡å¡‘ä¸º 2D ç½‘æ ¼
            delta_mean_2d = delta_mean.reshape(grid_size, grid_size)
            delta_std_2d = delta_std.reshape(grid_size, grid_size)

            # ç¬¬ä¸€è¡Œï¼šå¹³å‡ delta å€¼
            ax = axes[0, layer_idx + 1]
            im = ax.imshow(delta_mean_2d, cmap='viridis', interpolation='nearest')
            ax.set_title(f'Layer {layer_idx}\nDelta Mean', fontsize=11, fontweight='bold')
            ax.axis('off')
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

            # ç¬¬äºŒè¡Œï¼šdelta æ ‡å‡†å·®
            ax = axes[1, layer_idx + 1]
            im = ax.imshow(delta_std_2d, cmap='plasma', interpolation='nearest')
            ax.set_title(f'Layer {layer_idx}\nDelta Std', fontsize=11, fontweight='bold')
            ax.axis('off')
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        plt.suptitle('Delta Spatial Distribution', fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Delta spatial distribution saved: {save_path}")

    def plot_delta_statistics(
            self,
            deltas_list: List[Dict[str, torch.Tensor]],
            labels: List[int],
            save_name: str = "delta_statistics.png"
    ):
        """ç»Ÿè®¡åˆ†æå¤šä¸ªæ ·æœ¬çš„ delta å€¼

        Args:
            deltas_list: å¤šä¸ªæ ·æœ¬çš„ delta å­—å…¸åˆ—è¡¨
            labels: å¯¹åº”çš„æ ‡ç­¾
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_layers = len(deltas_list[0])

        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # 1. Delta å€¼åˆ†å¸ƒï¼ˆå„å±‚çš„ç›´æ–¹å›¾ï¼‰
        ax = axes[0, 0]
        for layer_idx in range(num_layers):
            all_deltas = []
            for deltas in deltas_list:
                delta = deltas[f'layer_{layer_idx}'].numpy().flatten()
                all_deltas.extend(delta)

            ax.hist(all_deltas, bins=50, alpha=0.6, label=f'Layer {layer_idx}', density=True)

        ax.set_xlabel('Delta Value', fontsize=12, fontweight='bold')
        ax.set_ylabel('Density', fontsize=12, fontweight='bold')
        ax.set_title('Delta Value Distribution (Layer Comparison)', fontsize=13, fontweight='bold')
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)

        # 2. Delta å‡å€¼éšå±‚å˜åŒ–
        ax = axes[0, 1]
        layer_means = []
        layer_stds = []

        for layer_idx in range(num_layers):
            all_deltas = []
            for deltas in deltas_list:
                delta = deltas[f'layer_{layer_idx}'].numpy().flatten()
                all_deltas.extend(delta)

            layer_means.append(np.mean(all_deltas))
            layer_stds.append(np.std(all_deltas))

        x = np.arange(num_layers)
        ax.errorbar(x, layer_means, yerr=layer_stds, marker='o', linewidth=2,
                    markersize=8, capsize=5, capthick=2)
        ax.set_xlabel('Layer Index', fontsize=12, fontweight='bold')
        ax.set_ylabel('Delta Mean Â± Std', fontsize=12, fontweight='bold')
        ax.set_title('Delta Statistics vs Layer Depth', fontsize=13, fontweight='bold')
        ax.set_xticks(x)
        ax.grid(True, alpha=0.3)

        # 3. ä¸åŒç±»åˆ«çš„ Delta æ¨¡å¼
        ax = axes[1, 0]
        class_deltas = {i: [] for i in range(10)}

        for deltas, label in zip(deltas_list, labels):
            # è®¡ç®—æ‰€æœ‰å±‚çš„å¹³å‡ delta
            all_layer_deltas = []
            for layer_idx in range(num_layers):
                delta = deltas[f'layer_{layer_idx}'].mean().item()
                all_layer_deltas.append(delta)
            class_deltas[label].append(np.mean(all_layer_deltas))

        class_means = [np.mean(class_deltas[i]) if len(class_deltas[i]) > 0 else 0
                       for i in range(10)]

        bars = ax.bar(range(10), class_means, color='steelblue', edgecolor='black')
        ax.set_xlabel('Digit Class', fontsize=12, fontweight='bold')
        ax.set_ylabel('Mean Delta Value', fontsize=12, fontweight='bold')
        ax.set_title('Delta Response by Class', fontsize=13, fontweight='bold')
        ax.set_xticks(range(10))
        ax.grid(True, axis='y', alpha=0.3)

        # 4. Delta å˜åŒ–å¹…åº¦ï¼ˆå±‚é—´å·®å¼‚ï¼‰
        ax = axes[1, 1]
        layer_changes = []

        for i in range(num_layers - 1):
            changes = []
            for deltas in deltas_list:
                delta_curr = deltas[f'layer_{i}'].mean().item()
                delta_next = deltas[f'layer_{i + 1}'].mean().item()
                changes.append(abs(delta_next - delta_curr))
            layer_changes.append(changes)

        bp = ax.boxplot(layer_changes, labels=[f'{i}â†’{i + 1}' for i in range(num_layers - 1)])
        ax.set_xlabel('Layer Transition', fontsize=12, fontweight='bold')
        ax.set_ylabel('|Delta Change|', fontsize=12, fontweight='bold')
        ax.set_title('Inter-layer Delta Change', fontsize=13, fontweight='bold')
        ax.grid(True, axis='y', alpha=0.3)

        plt.suptitle('Delta Statistical Analysis', fontsize=15, fontweight='bold', y=0.995)
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Delta statistics saved: {save_path}")

    def plot_delta_heatmap(
            self,
            image: np.ndarray,
            deltas: Dict[str, torch.Tensor],
            prediction: int,
            true_label: int,
            save_name: str = "delta_heatmap.png"
    ):
        """ç”Ÿæˆ delta çƒ­åŠ›å›¾å åŠ åˆ°åŸå›¾

        Args:
            image: åŸå§‹å›¾åƒ
            deltas: delta å€¼
            prediction: é¢„æµ‹
            true_label: çœŸå®æ ‡ç­¾
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_layers = len(deltas)
        fig, axes = plt.subplots(2, num_layers // 2, figsize=(16, 8))
        axes = axes.flatten()

        n_patches = deltas['layer_0'].shape[0]
        grid_size = int(np.sqrt(n_patches))

        for layer_idx in range(num_layers):
            ax = axes[layer_idx]

            # è®¡ç®— delta å‡å€¼å¹¶é‡å¡‘
            delta = deltas[f'layer_{layer_idx}'].mean(dim=1).numpy()
            delta_2d = delta.reshape(grid_size, grid_size)

            # ä¸Šé‡‡æ ·åˆ°åŸå›¾å¤§å°
            delta_upsampled = zoom(delta_2d, 28 / grid_size, order=1)

            # æ˜¾ç¤ºåŸå›¾
            ax.imshow(image.squeeze(), cmap='gray', alpha=0.5)

            # å åŠ  delta çƒ­åŠ›å›¾
            im = ax.imshow(delta_upsampled, cmap='hot', alpha=0.5)
            ax.set_title(f'Layer {layer_idx} Delta Heatmap', fontsize=11, fontweight='bold')
            ax.axis('off')
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        plt.suptitle(f'Delta Heatmap Overlay (True: {true_label}, Pred: {prediction})',
                     fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Delta heatmap saved: {save_path}")

    def plot_delta_heatmap_extended(
            self,
            image: np.ndarray,
            deltas: Dict[str, torch.Tensor],
            prediction: int,
            true_label: int,
            save_name: str = "delta_heatmap_extended.png"
    ):
        """æ‰©å±•ç‰ˆï¼šåŒæ—¶æ˜¾ç¤ºå‡å€¼å’ŒTop-3é€šé“"""
        num_layers = len(deltas)
        n_patches = deltas['layer_0'].shape[0]
        grid_size = int(np.sqrt(n_patches))

        # æ¯å±‚5åˆ—ï¼šåŸå›¾ + å‡å€¼ + Top-3é€šé“
        fig, axes = plt.subplots(num_layers, 5, figsize=(20, 4 * num_layers))

        if num_layers == 1:
            axes = axes.reshape(1, -1)

        for layer_idx in range(num_layers):
            delta_raw = deltas[f'layer_{layer_idx}']

            # åŸå›¾
            # axes[layer_idx, 0].imshow(image.squeeze(), cmap='gray')
            display_img = self.process_image_for_plot(image)
            axes[layer_idx, 0].imshow(display_img)

            axes[layer_idx, 0].set_title(f'Layer {layer_idx}\nOriginal', fontsize=10)
            axes[layer_idx, 0].axis('off')

            # å‡å€¼å›¾ï¼ˆæ‰€æœ‰é€šé“å¹³å‡ï¼‰
            delta_mean = delta_raw.mean(dim=1).numpy()
            delta_2d = delta_mean.reshape(grid_size, grid_size)
            delta_upsampled = zoom(delta_2d, 28 / grid_size, order=1)

            ax = axes[layer_idx, 1]
            # ax.imshow(image.squeeze(), cmap='gray', alpha=0.5)
            ax.imshow(display_img, alpha=0.5)

            im = ax.imshow(delta_upsampled, cmap='hot', alpha=0.5)
            ax.set_title('All Channels\nMean', fontsize=10, fontweight='bold')
            ax.axis('off')
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

            # Top-3 é€šé“
            channel_variance = delta_raw.var(dim=0)
            top_channels = torch.topk(channel_variance, k=3).indices

            for i, channel_idx in enumerate(top_channels):
                single_channel_delta = delta_raw[:, channel_idx].numpy()
                delta_2d = single_channel_delta.reshape(grid_size, grid_size)
                delta_upsampled = zoom(delta_2d, 28 / grid_size, order=1)

                ax = axes[layer_idx, i + 2]
                # ax.imshow(image.squeeze(), cmap='gray', alpha=0.5)
                ax.imshow(display_img, alpha=0.5)
                
                im = ax.imshow(delta_upsampled, cmap='hot', alpha=0.5)

                ch_var = channel_variance[channel_idx].item()
                ax.set_title(f'Ch {channel_idx.item()}\nVar={ch_var:.4f}',
                             fontsize=9, fontweight='bold')
                ax.axis('off')
                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        plt.suptitle(f'Delta Heatmap: Mean vs Top-3 High-Variance Channels\n'
                     f'(True: {true_label}, Pred: {prediction})',
                     fontsize=14, fontweight='bold', y=0.995)
        plt.tight_layout()

        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Delta extended heatmap saved: {save_path}")

    def plot_delta_channel_analysis(
            self,
            deltas: Dict[str, torch.Tensor],
            save_name: str = "delta_channel_analysis.png"
    ):
        """åˆ†æ delta åœ¨ä¸åŒé€šé“çš„åˆ†å¸ƒ

        Args:
            deltas: delta å€¼
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_layers = len(deltas)
        fig, axes = plt.subplots(1, num_layers, figsize=(5 * num_layers, 5))

        if num_layers == 1:
            axes = [axes]

        for layer_idx in range(num_layers):
            ax = axes[layer_idx]
            delta = deltas[f'layer_{layer_idx}'].numpy()  # (n_patches, d_inner)

            # è®¡ç®—æ¯ä¸ªé€šé“çš„ç»Ÿè®¡é‡
            channel_means = delta.mean(axis=0)  # (d_inner,)
            channel_stds = delta.std(axis=0)  # (d_inner,)

            # ç»˜åˆ¶æ¯ä¸ªé€šé“çš„åˆ†å¸ƒ
            x = np.arange(len(channel_means))
            ax.fill_between(x, channel_means - channel_stds, channel_means + channel_stds,
                            alpha=0.3, color='blue')
            ax.plot(x, channel_means, linewidth=2, color='darkblue')

            ax.set_xlabel('Channel Index', fontsize=12, fontweight='bold')
            ax.set_ylabel('Delta Value', fontsize=12, fontweight='bold')
            ax.set_title(f'Layer {layer_idx}\nChannel-wise Delta Distribution',
                         fontsize=13, fontweight='bold')
            ax.grid(True, alpha=0.3)

        plt.suptitle('Delta Channel-level Analysis', fontsize=15, fontweight='bold', y=1.00)
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… Delta channel analysis saved: {save_path}")

    def process_image_for_plot(self, image):
        """
        å°† (C, H, W) çš„ image å¤„ç†ä¸º imshow å¯ç”¨çš„ (H, W, C)
        å¹¶ä¸”è¿›è¡Œåå½’ä¸€åŒ–ä»¥ä¾¿æ˜¾ç¤ºæ­£å¸¸é¢œè‰²
        """
        # 1. ç§»é™¤ batch ç»´åº¦ (å¦‚æœå­˜åœ¨) -> (C, H, W)
        if len(image.shape) == 4:
            image = image.squeeze(0)
        
        # 2. Transpose: (C, H, W) -> (H, W, C)
        if isinstance(image, torch.Tensor):
            image = image.cpu().permute(1, 2, 0).numpy()
        elif isinstance(image, np.ndarray):
            # å¦‚æœå·²ç»æ˜¯ numpyï¼Œæ£€æŸ¥ shape
            if image.shape[0] == 3: # (3, 32, 32)
                image = np.transpose(image, (1, 2, 0))
        
        # 3. åå½’ä¸€åŒ– (é’ˆå¯¹ CIFAR-10 çš„ mean/std)
        # mean = (0.4914, 0.4822, 0.4465)
        # std = (0.2023, 0.1994, 0.2010)
        mean = np.array([0.4914, 0.4822, 0.4465])
        std = np.array([0.2023, 0.1994, 0.2010])
        
        image = std * image + mean
        image = np.clip(image, 0, 1) # é™åˆ¶åœ¨ 0-1 ä¹‹é—´
        
        return image



def load_model(model_path: str, device: torch.device) -> VisionMamba:
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ Loading model: {model_path}")
    model = create_vision_mamba_mnist(d_model=128, patch_size=1)
    checkpoint = torch.load(model_path, map_location=device)

    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ… Model loaded successfully")
    else:
        model.load_state_dict(checkpoint)
        print(f"âœ… Model loaded successfully")

    return model

def get_test_loader(batch_size: int = 1, data_dir: str = "./data") -> DataLoader:
    """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ (å·²ä¿®æ­£ä¸º CIFAR-10 ä»¥åŒ¹é…è®­ç»ƒè„šæœ¬)"""
    
    # 1. ä½¿ç”¨ train.py ä¸­å®šä¹‰çš„ CIFAR-10 å‡å€¼å’Œæ ‡å‡†å·®
    cifar_mean = (0.4914, 0.4822, 0.4465)
    cifar_std = (0.2023, 0.1994, 0.2010)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(cifar_mean, cifar_std)
    ])

    # 2. ä¿®æ”¹ä¸º CIFAR10 æ•°æ®é›†ï¼Œè€Œä¸æ˜¯ FashionMNIST
    test_dataset = datasets.CIFAR10(
        root=data_dir,
        train=False,
        download=True,
        transform=transform
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=True
    )

    return test_loader


# def get_test_loader(batch_size: int = 1, data_dir: str = "./data") -> DataLoader:
#     """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
#     transform = transforms.Compose([
#         transforms.ToTensor(),
#         transforms.Normalize((0.1307,), (0.3081,))
#     ])

#     test_dataset = datasets.FashionMNIST(
#         root=data_dir,
#         train=False,
#         download=True,
#         transform=transform
#     )

#     test_loader = DataLoader(
#         test_dataset,
#         batch_size=batch_size,
#         shuffle=True
#     )

#     return test_loader


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Mamba Delta Visualization')

    parser.add_argument('--model_path', type=str, required=True,
                        help='Path to model checkpoint')
    parser.add_argument('--data_dir', type=str, default='./data',
                        help='Dataset directory')
    parser.add_argument('--save_dir', type=str, default='./delta_viz',
                        help='Directory to save visualizations')
    parser.add_argument('--num_samples', type=int, default=16,
                        help='Number of samples to visualize')
    parser.add_argument('--device', type=str, default='cuda',
                        help='Device for inference')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  Using device: {device}\n")

    # é…ç½®å­—ä½“
    print("ğŸ”§ Configuring fonts...")
    configure_fonts()

    # åŠ è½½æ¨¡å‹
    model = load_model(args.model_path, device)

    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = DeltaVisualizer(model, device, args.save_dir)

    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ“¦ Loading test data...")
    test_loader = get_test_loader(batch_size=1, data_dir=args.data_dir)

    print(f"\n{'=' * 60}")
    print("ğŸ¨ Starting Delta Visualization")
    print(f"{'=' * 60}\n")

    # æ”¶é›†æ ·æœ¬çš„ delta å€¼
    deltas_list = []
    labels_list = []
    images_list = []
    predictions_list = []

    for idx, (image, label) in enumerate(tqdm(test_loader, desc="Extracting Delta", total=args.num_samples)):
        if idx >= args.num_samples:
            break

        image = image.to(device)

        # æå– delta
        deltas = visualizer.extract_delta_values(image)

        # è·å–é¢„æµ‹
        with torch.no_grad():
            logits = model(image)
            prediction = logits.argmax(dim=1).item()

        deltas_list.append(deltas)
        labels_list.append(label.item())
        images_list.append(image.cpu().numpy())
        predictions_list.append(prediction)

    # 1. å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„ç©ºé—´åˆ†å¸ƒ
    print("\n1/5 Generating Delta spatial distribution...")
    for i in range(min(4, len(images_list))):
        visualizer.plot_delta_spatial_distribution(
            images_list[i],
            deltas_list[i],
            predictions_list[i],
            labels_list[i],
            save_name=f"delta_spatial_sample_{i}.png"
        )

    # 2. Delta ç»Ÿè®¡åˆ†æ
    print("2/5 Generating Delta statistics...")
    visualizer.plot_delta_statistics(deltas_list, labels_list)

    # 3. Delta çƒ­åŠ›å›¾
    print("3/5 Generating Delta heatmaps...")
    for i in range(min(4, len(images_list))):
        visualizer.plot_delta_heatmap_extended(
            images_list[i],
            deltas_list[i],
            predictions_list[i],
            labels_list[i],
            save_name=f"delta_heatmap_extended_sample_{i}.png"
        )

    # 4. Delta é€šé“åˆ†æ
    print("4/5 Generating Delta channel analysis...")
    for i in range(min(2, len(deltas_list))):
        visualizer.plot_delta_channel_analysis(
            deltas_list[i],
            save_name=f"delta_channel_sample_{i}.png"
        )

    print(f"\n{'=' * 60}")
    print(f"âœ¨ Delta visualization complete!")
    print(f"ğŸ“ Results saved in: {args.save_dir}")
    print(f"{'=' * 60}\n")

    # æ‰“å°ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š Delta Statistics Summary:")
    for layer_idx in range(len(deltas_list[0])):
        all_deltas = []
        for deltas in deltas_list:
            delta = deltas[f'layer_{layer_idx}'].numpy().flatten()
            all_deltas.extend(delta)

        print(f"  Layer {layer_idx}:")
        print(f"    Mean: {np.mean(all_deltas):.6f}")
        print(f"    Std:  {np.std(all_deltas):.6f}")
        print(f"    Min:  {np.min(all_deltas):.6f}")
        print(f"    Max:  {np.max(all_deltas):.6f}")


if __name__ == "__main__":
    main()
