"""Vision Mamba æ¨ç†ä¸å¯è§†åŒ–è„šæœ¬

åŠŸèƒ½åŒ…æ‹¬ï¼š
    1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†
    2. å¯è§†åŒ–é¢„æµ‹ç»“æœ
    3. æ··æ·†çŸ©é˜µåˆ†æ
    4. é”™è¯¯æ ·æœ¬åˆ†æ
    5. æ³¨æ„åŠ›å›¾å¯è§†åŒ–ï¼ˆpatché‡è¦æ€§ï¼‰
    6. æ¨¡å‹æ€§èƒ½ç»Ÿè®¡

ä½¿ç”¨æ–¹æ³•:
    python inference.py --model_path ./checkpoints/best_model.pth
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import argparse
from pathlib import Path
from tqdm import tqdm
from typing import List, Tuple, Dict
import warnings

warnings.filterwarnings('ignore')

from vision_mamba import create_vision_mamba_mnist, VisionMamba

# è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
def set_chinese_font():
    # åŠ¨æ€é€‰æ‹©ç³»ç»Ÿå¯ç”¨å­—ä½“ï¼Œé¿å…ç¡¬ç¼–ç ä¸å¯ç”¨çš„å­—ä½“å
    from matplotlib import font_manager
    preferred = [
        'Noto Sans CJK SC', 'Noto Serif CJK SC',
        'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 'DejaVu Sans'
    ]
    available = {f.name for f in font_manager.fontManager.ttflist}
    for p in preferred:
        if p in available:
            plt.rcParams['font.sans-serif'] = [p]
            plt.rcParams['axes.unicode_minus'] = False
            print(f"å·²è®¾ç½®ä¸­æ–‡å­—ä½“ï¼š{p}")
            return p
    # å›é€€
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    print("æœªèƒ½æ‰¾åˆ°é¦–é€‰ä¸­æ–‡å­—ä½“ï¼Œå·²å›é€€åˆ° DejaVu Sans")
    return 'DejaVu Sans'


class ModelInference:
    """æ¨¡å‹æ¨ç†ç±»ï¼šå°è£…æ¨ç†å’Œåˆ†æåŠŸèƒ½"""

    def __init__(
            self,
            model: VisionMamba,
            device: torch.device,
            class_names: List[str] = None
    ):
        """åˆå§‹åŒ–æ¨ç†å™¨

        Args:
            model: è®­ç»ƒå¥½çš„Vision Mambaæ¨¡å‹
            device: æ¨ç†è®¾å¤‡
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
        """
        self.model = model.to(device)
        self.model.eval()
        self.device = device
        self.class_names = class_names or [str(i) for i in range(10)]

    @torch.no_grad()
    def predict_single(self, image: torch.Tensor) -> Tuple[int, torch.Tensor]:
        """é¢„æµ‹å•å¼ å›¾åƒ

        Args:
            image: è¾“å…¥å›¾åƒ shape (1, 28, 28) æˆ– (28, 28)

        Returns:
            pred_class: é¢„æµ‹ç±»åˆ«
            probs: ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ shape (10,)
        """
        # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
        if image.dim() == 2:
            image = image.unsqueeze(0)  # (28, 28) -> (1, 28, 28)
        if image.dim() == 3:
            image = image.unsqueeze(0)  # (1, 28, 28) -> (1, 1, 28, 28)

        image = image.to(self.device)

        # å‰å‘ä¼ æ’­
        logits = self.model(image)
        probs = torch.softmax(logits, dim=1)
        pred_class = probs.argmax(dim=1).item()

        return pred_class, probs.squeeze()

    @torch.no_grad()
    def predict_batch(
            self,
            data_loader: DataLoader,
            max_samples: int = None
    ) -> Dict[str, np.ndarray]:
        """æ‰¹é‡é¢„æµ‹å¹¶æ”¶é›†ç»“æœ

        Args:
            data_loader: æ•°æ®åŠ è½½å™¨
            max_samples: æœ€å¤§é¢„æµ‹æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰

        Returns:
            results: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        all_preds = []
        all_labels = []
        all_probs = []
        all_images = []

        total_samples = 0

        for images, labels in tqdm(data_loader, desc="æ¨ç†ä¸­"):
            if max_samples and total_samples >= max_samples:
                break

            images = images.to(self.device)
            logits = self.model(images)
            probs = torch.softmax(logits, dim=1)
            preds = probs.argmax(dim=1)

            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.numpy())
            all_probs.append(probs.cpu().numpy())
            all_images.append(images.cpu().numpy())

            total_samples += images.size(0)

        results = {
            'predictions': np.concatenate(all_preds),
            'labels': np.concatenate(all_labels),
            'probabilities': np.concatenate(all_probs),
            'images': np.concatenate(all_images)
        }

        return results

    @torch.no_grad()
    def get_patch_attention(self, image: torch.Tensor) -> np.ndarray:
        """è·å–patchçº§åˆ«çš„æ³¨æ„åŠ›æƒé‡ï¼ˆé€šè¿‡æœ€åä¸€å±‚çš„æ¿€æ´»å€¼è¿‘ä¼¼ï¼‰

        Args:
            image: è¾“å…¥å›¾åƒ shape (1, 1, 28, 28)

        Returns:
            attention_map: æ³¨æ„åŠ›å›¾ shape (7, 7) for patch_size=4
        """
        if image.dim() == 3:
            image = image.unsqueeze(0)

        image = image.to(self.device)

        # å‰å‘ä¼ æ’­åˆ°å½’ä¸€åŒ–å±‚ä¹‹å‰
        x = self.model.patch_embed(image)
        x = x + self.model.pos_embed
        x = self.model.pos_drop(x)

        for layer in self.model.layers:
            x = layer(x)

        # è®¡ç®—æ¯ä¸ªpatchçš„L2èŒƒæ•°ä½œä¸ºé‡è¦æ€§åº¦é‡
        attention = torch.norm(x, dim=-1).squeeze()  # shape (n_patches,)
        attention = attention.cpu().numpy()

        # é‡å¡‘ä¸º2Dç½‘æ ¼
        n_patches_per_side = int(np.sqrt(len(attention)))
        attention_map = attention.reshape(n_patches_per_side, n_patches_per_side)

        # å½’ä¸€åŒ–åˆ°[0, 1]
        attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min() + 1e-8)

        return attention_map


class Visualizer:
    """å¯è§†åŒ–ç±»ï¼šå°è£…å„ç§å¯è§†åŒ–åŠŸèƒ½"""

    def __init__(self, save_dir: str = "./visualizations"):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨

        Args:
            save_dir: å›¾åƒä¿å­˜ç›®å½•
        """
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®matplotlibæ ·å¼
        plt.style.use('seaborn-v0_8-darkgrid')
        sns.set_palette("husl")
        set_chinese_font()

    def plot_predictions(
            self,
            images: np.ndarray,
            predictions: np.ndarray,
            labels: np.ndarray,
            probabilities: np.ndarray,
            num_samples: int = 16,
            save_name: str = "predictions.png"
    ):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆç½‘æ ¼å¸ƒå±€ï¼‰

        Args:
            images: å›¾åƒæ•°ç»„ shape (N, 1, 28, 28)
            predictions: é¢„æµ‹ç»“æœ shape (N,)
            labels: çœŸå®æ ‡ç­¾ shape (N,)
            probabilities: é¢„æµ‹æ¦‚ç‡ shape (N, 10)
            num_samples: æ˜¾ç¤ºæ ·æœ¬æ•°
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_samples = min(num_samples, len(images))
        cols = 4
        rows = (num_samples + cols - 1) // cols

        fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))
        axes = axes.flatten()

        for idx in range(num_samples):
            ax = axes[idx]

            # æ˜¾ç¤ºå›¾åƒ
            img = images[idx].squeeze()
            ax.imshow(img, cmap='gray')

            # è·å–é¢„æµ‹ä¿¡æ¯
            pred = predictions[idx]
            true = labels[idx]
            prob = probabilities[idx][pred]

            # è®¾ç½®æ ‡é¢˜ï¼ˆæ­£ç¡®ä¸ºç»¿è‰²ï¼Œé”™è¯¯ä¸ºçº¢è‰²ï¼‰
            is_correct = pred == true
            color = 'green' if is_correct else 'red'
            title = f"é¢„æµ‹:{pred} (çœŸå®:{true})\nç½®ä¿¡åº¦:{prob:.2%}"
            ax.set_title(title, color=color, fontsize=10, fontweight='bold')

            ax.axis('off')

        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(num_samples, len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: {save_path}")

    def plot_confusion_matrix(
            self,
            predictions: np.ndarray,
            labels: np.ndarray,
            class_names: List[str],
            save_name: str = "confusion_matrix.png"
    ):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ

        Args:
            predictions: é¢„æµ‹ç»“æœ
            labels: çœŸå®æ ‡ç­¾
            class_names: ç±»åˆ«åç§°
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(labels, predictions)

        # ç»˜åˆ¶çƒ­å›¾
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names,
            ax=ax,
            cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}
        )

        ax.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12, fontweight='bold')
        ax.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=12, fontweight='bold')
        ax.set_title('æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold', pad=20)

        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")

    def plot_error_analysis(
            self,
            images: np.ndarray,
            predictions: np.ndarray,
            labels: np.ndarray,
            probabilities: np.ndarray,
            num_errors: int = 20,
            save_name: str = "error_analysis.png"
    ):
        """åˆ†æå¹¶å¯è§†åŒ–é”™è¯¯æ ·æœ¬

        Args:
            images: å›¾åƒæ•°ç»„
            predictions: é¢„æµ‹ç»“æœ
            labels: çœŸå®æ ‡ç­¾
            probabilities: é¢„æµ‹æ¦‚ç‡
            num_errors: æ˜¾ç¤ºçš„é”™è¯¯æ ·æœ¬æ•°
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        # æ‰¾å‡ºæ‰€æœ‰é”™è¯¯æ ·æœ¬
        error_mask = predictions != labels
        error_indices = np.where(error_mask)[0]

        if len(error_indices) == 0:
            print("ğŸ‰ æ²¡æœ‰å‘ç°é”™è¯¯æ ·æœ¬ï¼æ¨¡å‹è¡¨ç°å®Œç¾ï¼")
            return

        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼ˆé«˜ç½®ä¿¡åº¦é”™è¯¯æ›´å€¼å¾—å…³æ³¨ï¼‰
        error_confidences = probabilities[error_indices, predictions[error_indices]]
        sorted_indices = error_indices[np.argsort(error_confidences)[::-1]]

        num_errors = min(num_errors, len(sorted_indices))
        cols = 5
        rows = (num_errors + cols - 1) // cols

        fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))
        axes = axes.flatten()

        for i, idx in enumerate(sorted_indices[:num_errors]):
            ax = axes[i]

            img = images[idx].squeeze()
            pred = predictions[idx]
            true = labels[idx]
            conf = probabilities[idx][pred]

            ax.imshow(img, cmap='gray')
            ax.set_title(
                f"é¢„æµ‹:{pred}â†’çœŸå®:{true}\nç½®ä¿¡åº¦:{conf:.2%}",
                color='red',
                fontsize=9,
                fontweight='bold'
            )
            ax.axis('off')

        # éšè—å¤šä½™çš„å­å›¾
        for i in range(num_errors, len(axes)):
            axes[i].axis('off')

        plt.suptitle(
            f'é”™è¯¯æ ·æœ¬åˆ†æ (å…±{len(error_indices)}ä¸ªé”™è¯¯)',
            fontsize=14,
            fontweight='bold',
            y=1.02
        )
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… é”™è¯¯åˆ†æå·²ä¿å­˜: {save_path}")
        print(f"   é”™è¯¯ç‡: {len(error_indices) / len(predictions) * 100:.2f}%")

    def plot_probability_distribution(
            self,
            probabilities: np.ndarray,
            predictions: np.ndarray,
            labels: np.ndarray,
            save_name: str = "probability_distribution.png"
    ):
        """ç»˜åˆ¶é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ

        Args:
            probabilities: é¢„æµ‹æ¦‚ç‡
            predictions: é¢„æµ‹ç»“æœ
            labels: çœŸå®æ ‡ç­¾
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        # è·å–é¢„æµ‹ç±»åˆ«çš„ç½®ä¿¡åº¦
        confidences = probabilities[np.arange(len(predictions)), predictions]

        # åŒºåˆ†æ­£ç¡®å’Œé”™è¯¯çš„é¢„æµ‹
        correct_mask = predictions == labels
        correct_conf = confidences[correct_mask]
        wrong_conf = confidences[~correct_mask]

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # å·¦å›¾ï¼šç›´æ–¹å›¾å¯¹æ¯”
        ax = axes[0]
        bins = np.linspace(0, 1, 30)
        ax.hist(correct_conf, bins=bins, alpha=0.7, label='æ­£ç¡®é¢„æµ‹', color='green', edgecolor='black')
        ax.hist(wrong_conf, bins=bins, alpha=0.7, label='é”™è¯¯é¢„æµ‹', color='red', edgecolor='black')
        ax.set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦', fontsize=12, fontweight='bold')
        ax.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12, fontweight='bold')
        ax.set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)

        # å³å›¾ï¼šç»Ÿè®¡ä¿¡æ¯
        ax = axes[1]
        ax.axis('off')

        stats_text = f"""
        ğŸ“Š ç»Ÿè®¡ä¿¡æ¯
        {'=' * 40}

        æ€»æ ·æœ¬æ•°: {len(predictions):,}
        æ­£ç¡®é¢„æµ‹: {np.sum(correct_mask):,}
        é”™è¯¯é¢„æµ‹: {np.sum(~correct_mask):,}
        å‡†ç¡®ç‡: {np.mean(correct_mask) * 100:.2f}%

        ç½®ä¿¡åº¦ç»Ÿè®¡:
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {np.mean(correct_conf):.4f}
        é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {np.mean(wrong_conf) if len(wrong_conf) > 0 else 0:.4f}

        é«˜ç½®ä¿¡åº¦æ­£ç¡® (>0.9): {np.sum(correct_conf > 0.9):,}
        é«˜ç½®ä¿¡åº¦é”™è¯¯ (>0.9): {np.sum(wrong_conf > 0.9) if len(wrong_conf) > 0 else 0:,}
        ä½ç½®ä¿¡åº¦æ­£ç¡® (<0.5): {np.sum(correct_conf < 0.5):,}
        """

        ax.text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center',
                fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ¦‚ç‡åˆ†å¸ƒå·²ä¿å­˜: {save_path}")

    def plot_attention_maps(
            self,
            images: np.ndarray,
            attention_maps: List[np.ndarray],
            predictions: np.ndarray,
            labels: np.ndarray,
            num_samples: int = 8,
            save_name: str = "attention_maps.png"
    ):
        """å¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼ˆpatché‡è¦æ€§ï¼‰

        Args:
            images: åŸå§‹å›¾åƒ
            attention_maps: æ³¨æ„åŠ›å›¾åˆ—è¡¨
            predictions: é¢„æµ‹ç»“æœ
            labels: çœŸå®æ ‡ç­¾
            num_samples: æ˜¾ç¤ºæ ·æœ¬æ•°
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_samples = min(num_samples, len(images))

        fig, axes = plt.subplots(num_samples, 3, figsize=(10, 3 * num_samples))
        if num_samples == 1:
            axes = axes.reshape(1, -1)

        for i in range(num_samples):
            # åŸå§‹å›¾åƒ
            ax = axes[i, 0]
            ax.imshow(images[i].squeeze(), cmap='gray')
            ax.set_title(f'åŸå›¾\nçœŸå®:{labels[i]}', fontsize=10)
            ax.axis('off')

            # æ³¨æ„åŠ›å›¾
            ax = axes[i, 1]
            im = ax.imshow(attention_maps[i], cmap='hot', interpolation='nearest')
            ax.set_title('Patché‡è¦æ€§', fontsize=10)
            ax.axis('off')
            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

            # å åŠ å›¾
            ax = axes[i, 2]
            # å°†æ³¨æ„åŠ›å›¾ä¸Šé‡‡æ ·åˆ°åŸå›¾å¤§å°
            from scipy.ndimage import zoom
            attention_upsampled = zoom(attention_maps[i], 28 / attention_maps[i].shape[0], order=1)
            ax.imshow(images[i].squeeze(), cmap='gray', alpha=0.6)
            ax.imshow(attention_upsampled, cmap='hot', alpha=0.4)
            ax.set_title(f'å åŠ å›¾\né¢„æµ‹:{predictions[i]}', fontsize=10)
            ax.axis('off')

        plt.suptitle('Patchæ³¨æ„åŠ›å¯è§†åŒ–', fontsize=14, fontweight='bold', y=0.995)
        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ³¨æ„åŠ›å›¾å·²ä¿å­˜: {save_path}")

    def plot_per_class_accuracy(
            self,
            predictions: np.ndarray,
            labels: np.ndarray,
            class_names: List[str],
            save_name: str = "per_class_accuracy.png"
    ):
        """ç»˜åˆ¶æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡

        Args:
            predictions: é¢„æµ‹ç»“æœ
            labels: çœŸå®æ ‡ç­¾
            class_names: ç±»åˆ«åç§°
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        num_classes = len(class_names)
        class_correct = np.zeros(num_classes)
        class_total = np.zeros(num_classes)

        for label, pred in zip(labels, predictions):
            class_total[label] += 1
            if label == pred:
                class_correct[label] += 1

        class_accuracy = class_correct / (class_total + 1e-8) * 100

        fig, ax = plt.subplots(figsize=(12, 6))

        bars = ax.bar(class_names, class_accuracy, color='steelblue', edgecolor='black', linewidth=1.5)

        # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼
        for i, (bar, acc, total) in enumerate(zip(bars, class_accuracy, class_total)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height,
                    f'{acc:.1f}%\n({int(class_correct[i])}/{int(total)})',
                    ha='center', va='bottom', fontsize=9, fontweight='bold')

        # æ·»åŠ å¹³å‡çº¿
        avg_acc = np.mean(class_accuracy)
        ax.axhline(y=avg_acc, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡å‡†ç¡®ç‡: {avg_acc:.2f}%')

        ax.set_xlabel('ç±»åˆ«', fontsize=12, fontweight='bold')
        ax.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12, fontweight='bold')
        ax.set_title('å„ç±»åˆ«å‡†ç¡®ç‡åˆ†æ', fontsize=14, fontweight='bold', pad=20)
        ax.set_ylim([0, 105])
        ax.legend(fontsize=10)
        ax.grid(True, axis='y', alpha=0.3)

        plt.tight_layout()
        save_path = self.save_dir / save_name
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… å„ç±»åˆ«å‡†ç¡®ç‡å·²ä¿å­˜: {save_path}")


def load_model(model_path: str, device: torch.device) -> VisionMamba:
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹

    Args:
        model_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        device: è®¾å¤‡

    Returns:
        model: åŠ è½½å¥½çš„æ¨¡å‹
    """
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")

    # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    model = create_vision_mamba_mnist()
    model = torch.compile(model)

    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)

    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Epoch: {checkpoint.get('epoch', 'Unknown')})")
        if 'best_val_acc' in checkpoint:
            print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint['best_val_acc']:.2f}%")
    else:
        model.load_state_dict(checkpoint)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

    return model


def get_test_loader(batch_size: int = 128, data_dir: str = "./data") -> DataLoader:
    """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨

    Args:
        batch_size: æ‰¹æ¬¡å¤§å°
        data_dir: æ•°æ®é›†ç›®å½•

    Returns:
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    test_dataset = datasets.MNIST(
        root=data_dir,
        train=False,
        download=True,
        transform=transform
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    return test_loader


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Vision Mambaæ¨ç†ä¸å¯è§†åŒ–')

    parser.add_argument('--model_path', type=str, required=True,
                        help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--data_dir', type=str, default='./data',
                        help='æ•°æ®é›†ç›®å½•')
    parser.add_argument('--save_dir', type=str, default='./visualizations',
                        help='å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=128,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_samples', type=int, default=None,
                        help='æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰')
    parser.add_argument('--device', type=str, default='cuda',
                        help='æ¨ç†è®¾å¤‡')
    parser.add_argument('--show_attention', action='store_true',
                        help='æ˜¯å¦æ˜¾ç¤ºæ³¨æ„åŠ›å›¾ï¼ˆè¾ƒæ…¢ï¼‰')

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„æ¨ç†å’Œå¯è§†åŒ–æµç¨‹"""
    args = parse_args()

    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}\n")

    # åŠ è½½æ¨¡å‹
    model = load_model(args.model_path, device)

    # åˆ›å»ºæ¨ç†å™¨
    inference = ModelInference(model, device)

    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = Visualizer(args.save_dir)

    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®...")
    test_loader = get_test_loader(args.batch_size, args.data_dir)

    # æ‰¹é‡æ¨ç†
    print("\nğŸ”® å¼€å§‹æ¨ç†...")
    results = inference.predict_batch(test_loader, args.max_samples)

    images = results['images']
    predictions = results['predictions']
    labels = results['labels']
    probabilities = results['probabilities']

    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    accuracy = np.mean(predictions == labels) * 100
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š æ€»ä½“å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"{'=' * 60}\n")

    # æ‰“å°åˆ†ç±»æŠ¥å‘Š
    print("ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(labels, predictions, target_names=[str(i) for i in range(10)]))

    # å¼€å§‹å¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")

    # 1. é¢„æµ‹ç»“æœå±•ç¤º
    print("  1/6 ç»˜åˆ¶é¢„æµ‹ç»“æœ...")
    visualizer.plot_predictions(images, predictions, labels, probabilities, num_samples=16)

    # 2. æ··æ·†çŸ©é˜µ
    print("  2/6 ç»˜åˆ¶æ··æ·†çŸ©é˜µ...")
    visualizer.plot_confusion_matrix(predictions, labels, [str(i) for i in range(10)])

    # 3. é”™è¯¯åˆ†æ
    print("  3/6 åˆ†æé”™è¯¯æ ·æœ¬...")
    visualizer.plot_error_analysis(images, predictions, labels, probabilities, num_errors=20)

    # 4. æ¦‚ç‡åˆ†å¸ƒ
    print("  4/6 ç»˜åˆ¶æ¦‚ç‡åˆ†å¸ƒ...")
    visualizer.plot_probability_distribution(probabilities, predictions, labels)

    # 5. å„ç±»åˆ«å‡†ç¡®ç‡
    print("  5/6 ç»˜åˆ¶å„ç±»åˆ«å‡†ç¡®ç‡...")
    visualizer.plot_per_class_accuracy(predictions, labels, [str(i) for i in range(10)])

    # 6. æ³¨æ„åŠ›å›¾ï¼ˆå¯é€‰ï¼Œæ¯”è¾ƒæ…¢ï¼‰
    if args.show_attention:
        print("  6/6 ç”Ÿæˆæ³¨æ„åŠ›å›¾ï¼ˆè¾ƒæ…¢ï¼‰...")
        attention_maps = []
        num_attention_samples = min(8, len(images))

        for i in tqdm(range(num_attention_samples), desc="è®¡ç®—æ³¨æ„åŠ›"):
            img_tensor = torch.from_numpy(images[i:i + 1])
            attention = inference.get_patch_attention(img_tensor)
            attention_maps.append(attention)

        visualizer.plot_attention_maps(
            images[:num_attention_samples],
            attention_maps,
            predictions[:num_attention_samples],
            labels[:num_attention_samples]
        )
    else:
        print("  6/6 è·³è¿‡æ³¨æ„åŠ›å›¾ï¼ˆä½¿ç”¨ --show_attention å¯ç”¨ï¼‰")

    print(f"\n{'=' * 60}")
    print(f"âœ¨ æ‰€æœ‰å¯è§†åŒ–å·²å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.save_dir}")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()