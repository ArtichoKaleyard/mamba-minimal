{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531467a2-5160-4073-a990-0d81d574b014",
   "metadata": {},
   "source": [
    "## (1) Load model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9337043-4e7a-4b20-9d89-6c6257245334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:27.212027600Z",
     "start_time": "2026-01-07T04:12:22.796915900Z"
    }
   },
   "source": [
    "import torch\n",
    "from model import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# One of:\n",
    "#     'state-spaces/mamba-2.8b-slimpj'\n",
    "#     'state-spaces/mamba-2.8b'\n",
    "#     'state-spaces/mamba-1.4b'\n",
    "#     'state-spaces/mamba-790m'\n",
    "#     'state-spaces/mamba-370m'\n",
    "#     'state-spaces/mamba-130m'\n",
    "pretrained_model_name = 'state-spaces/mamba-370m'\n",
    "\n",
    "# 1. 定义设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 将模型加载并移至 GPU\n",
    "model = Mamba.from_pretrained(pretrained_model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "0b2efb17-37ad-472b-b029-9567acf17629",
   "metadata": {},
   "source": [
    "## (2) Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4b2d62d-0d95-4a3f-bd98-aa37e3f26b39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:27.233684Z",
     "start_time": "2026-01-07T04:12:27.224526500Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def generate(model,\n",
    "             tokenizer,\n",
    "             prompt: str,\n",
    "             n_tokens_to_gen: int = 50,\n",
    "             sample: bool = True,\n",
    "             top_k: int = 40):\n",
    "    model.eval()\n",
    "\n",
    "    # 3. 将输入的 input_ids 移至 GPU\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        with torch.no_grad():\n",
    "            # 这里 input_ids 已经在 GPU 上了，所以 model 的计算会在 GPU 上进行\n",
    "            indices_to_input = input_ids\n",
    "            next_token_logits = model(indices_to_input)[:, -1]\n",
    "        \n",
    "        probs = F.softmax(next_token_logits, dim=-1)\n",
    "        (batch, vocab_size) = probs.shape\n",
    "        \n",
    "        if top_k is not None:\n",
    "            (values, indices) = torch.topk(probs, k=top_k)\n",
    "            probs[probs < values[:, -1, None]] = 0\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # 在进行采样或取极大值时，生成的 next_indices 会自动继承 input_ids 的设备\n",
    "        if sample:\n",
    "            next_indices = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "    \n",
    "    return output_completions"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ee877143-2042-4579-8042-a96db6200517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:36.800295900Z",
     "start_time": "2026-01-07T04:12:27.234684700Z"
    }
   },
   "source": [
    "print(generate(model, tokenizer, 'Mamba is the'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba is the first full-length album by British rock songwriter Dave Eringa (Eddie Troutman). Mamba was released in 1983. Two singles were released from the album. Mamba was used for The Last Temptation of Christ.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "65d70549-597f-49ca-9185-2184d2576f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:46.032319800Z",
     "start_time": "2026-01-07T04:12:36.815549400Z"
    }
   },
   "source": [
    "print(generate(model, tokenizer, 'John: Hi!\\nSally:'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: Hi!\n",
      "Sally: Hi John.\n",
      "John: Good to see you.\n",
      "Sally: Oh my God, I know.\n",
      "John: This is a problem.\n",
      "Sally: I really miss you, though, baby.\n",
      "John: I know, we\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6d419fc9-066b-4818-812c-2f1952528bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:52.944868600Z",
     "start_time": "2026-01-07T04:12:46.046304900Z"
    }
   },
   "source": [
    "print(generate(model, tokenizer, 'The meaning of life is '))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is \n",
      "To be a king is \n",
      "to know the sky is blue.\n",
      "To have your mind is \n",
      "to know that you are alive.\n",
      "To have the strength is \n",
      "to know that you are strong.\n",
      "As a king,\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "2b189e6e-6a96-4770-88cf-7c5de22cb321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:59.909594400Z",
     "start_time": "2026-01-07T04:12:52.959654300Z"
    }
   },
   "source": [
    "print(generate(model, tokenizer, 'def reverse_string('))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def reverse_string(str):\n",
      "        # Reverse a string that has a '.' at the beginning\n",
      "        return str.replace('..', '_').join([str.replace(':', '').replace('.', '')\n",
      "            for i in range(len(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "be3afb51-5093-4c64-ac3f-43c2e6b20b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:59.929883900Z",
     "start_time": "2026-01-07T04:12:59.924302800Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "6531acc0-b18f-472a-8e99-cee64dd51cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:59.935507200Z",
     "start_time": "2026-01-07T04:12:59.930382400Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "d0efe197-891a-4ab8-8cea-413d1fb1acda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:59.940440600Z",
     "start_time": "2026-01-07T04:12:59.936010900Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "2e99509b-df7b-4bac-b6a2-669f601ec1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T04:12:59.945666700Z",
     "start_time": "2026-01-07T04:12:59.940939700Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
